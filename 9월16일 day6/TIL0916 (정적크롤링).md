# TIL0916 (정적크롤링)

## (1) 정적크롤링

> R 세션이 다르면  library()로 패키지를 다시 불러와야한다.
>
> css 선택자로 접근하면 하위 컨텐트 내용을 구분해서 가져오기 어렵다.
>
> 따라서 이렇게 원하는 컨텐트 내용을 가져오려는 경우 XPath를 활용한다.

```R
##### 정적 웹 크롤링과 스크래핑 #####
##### 영화리뷰 크롤링 #####
# 단일 페이지(rvest 패키지 사용)
library(rvest)
text<-NULL; title<-NULL; point<-NULL; review<-NULL; page<-NULL
url<- "http://movie.naver.com/movie/point/af/list.nhn?page=1"
text <- read_html(url, encoding="CP949"); text # CP949 = "charset=euc-kr" (반드시 대문자)
# read_html()는 rvest가 아닌 XML2 패키지에서 불러온 함수

# 영화제목
nodes <- html_nodes(text, ".movie")
title <- html_text(nodes); title

# 영화평점
nodes <- html_nodes(text, ".title em")
point <- html_text(nodes); point

# 영화리뷰 
nodes <- html_nodes(text, xpath="//*[@id='old_content']/table/tbody/tr/td[2]/text()")
nodes <- html_text(nodes, trim=TRUE); nodes
review <- nodes[nchar(nodes) > 0]; review

page <- data.frame(title, point, review)
write.csv(page, "movie_reviews.csv") # 데이터프레임파일을 현재 working directory에 csv로 저장

```



```R
# 컨텐츠가 비어있는 경우를 처리 (리뷰를 남기지 않은 평점까지 처리)
text<-NULL; vtitle<-NULL; vpoint<-NULL; vreview<-NULL; page<-NULL
url<- "http://movie.naver.com/movie/point/af/list.nhn?page=1"
text <- read_html(url,  encoding="CP949"); text
for (index in 1:10) {
  # 영화제목
  node <- html_nodes(text, paste0("#old_content > table > tbody > tr:nth-child(", index, ") > td.title > a.movie.color_b"))
  title <- html_text(node)
  vtitle[index] <- title
    
  # 영화평점
  node <- html_nodes(text, paste0("#old_content > table > tbody > tr:nth-child(", index,") > td.title > div > em"))
  point <- html_text(node)
  vpoint <- c(vpoint, point)
    
  # 영화리뷰 
  node <- html_nodes(text, xpath=paste0('//*[@id="old_content"]/table/tbody/tr[', index,"]/td[2]/text()"))
  node <- html_text(node, trim=TRUE)
  review = node[4] # 태그 간에 enter 값도 텍스트 돔객체 ""로 처리돼서 태그에서 4번째를 가져온 것
  vreview <- append(vreview, review) # append(벡터, values=추가할 값, after=추가될 위치)
}

page <- data.frame(vtitle, vpoint, vreview); View(page)
getwd(); setwd("C:/Rexam"); getwd()
write.csv(page, "movie_reviews1.csv")

```



```R
# 여러 페이지
site <- "http://movie.naver.com/movie/point/af/list.nhn?page="
text <- NULL
movie.review <- NULL
for(i in 1: 100) {
  url <- paste(site, i, sep="")
  text <- read_html(url,  encoding="CP949")
  nodes <- html_nodes(text, ".movie")
  title <- html_text(nodes)
  nodes <- html_nodes(text, ".title em")
  point <- html_text(nodes)
  nodes <- html_nodes(text, xpath="//*[@id='old_content']/table/tbody/tr/td[2]/text()")
  imsi <- html_text(nodes, trim=TRUE)
  review <- imsi[nchar(imsi) > 0]
  if(length(review) == 10) { # 한페이지안에 리뷰글이 없는 경우가 있으면 그 페이지를 버림(너무버림)
    page <- data.frame(title, point, review)
    movie.review <- rbind(movie.review, page)
  } else {
    cat(paste(i," 페이지에는 리뷰글이 생략된 데이터가 있어서 수집하지 않습니다.ㅜㅜ\n"))
  }
}
write.csv(movie.review, "movie_reviews2.csv")
```

